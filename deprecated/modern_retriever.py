# modern_retriever.py - å®Œå…¨ç°ä»£LangChainå†™æ³•
import os
from pathlib import Path
from typing import List, Dict, Optional

# 1. ç°ä»£å¯¼å…¥æ–¹å¼ - æ¯ä¸ªåŠŸèƒ½æœ‰ç‹¬ç«‹çš„ä¸“é—¨åŒ…
from langchain_chroma import Chroma  # ä¸“ç”¨ChromaåŒ…
from langchain_huggingface import HuggingFaceEmbeddings  # ä¸“ç”¨åµŒå…¥æ¨¡å‹åŒ…
from langchain_text_splitters import RecursiveCharacterTextSplitter  # ä¸“ç”¨æ–‡æœ¬åˆ†å‰²åŒ…
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain_core.documents import Document
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_core.runnables import RunnablePassthrough

class ModernEvidenceRetriever:
    """ç°ä»£å†™æ³•çš„è¯æ®æ£€ç´¢æ™ºèƒ½ä½“"""
    
    def __init__(self, data_path: str = "./data/rumors"):
        self.data_path = Path(data_path)
        self.vectorstore: Optional[Chroma] = None
        self.retriever: Optional[VectorStoreRetriever] = None
        
        # ä½¿ç”¨æ›´ç°ä»£çš„åµŒå…¥æ¨¡å‹é…ç½®
        self.embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-small-zh-v1.5",
            model_kwargs={"device": "cpu"},
            encode_kwargs={
                "normalize_embeddings": True,
                "batch_size": 32  # æ‰¹é‡å¤„ç†æé«˜æ•ˆç‡
            }
        )
        print("âœ… ç°ä»£åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    def build_knowledge_base(self, chunk_size: int = 400, chunk_overlap: int = 80):
        """æ„å»ºçŸ¥è¯†åº“ - ä½¿ç”¨ç°ä»£å‚æ•°é…ç½®"""
        
        # 1. åŠ è½½æ–‡æ¡£ï¼ˆä½¿ç”¨pathlibæ›´ç°ä»£ï¼‰
        if not self.data_path.exists():
            self.data_path.mkdir(parents=True, exist_ok=True)
            print(f"âš ï¸  æ•°æ®ç›®å½• {self.data_path} å·²åˆ›å»ºï¼Œè¯·æ·»åŠ  .txt æ–‡æ¡£")
            return False
        
        loader = DirectoryLoader(
            str(self.data_path), 
            glob="**/*.txt", 
            loader_cls=TextLoader,
            loader_kwargs={"autodetect_encoding": True}  # è‡ªåŠ¨æ£€æµ‹ç¼–ç 
        )
        
        documents = loader.load()
        if not documents:
            print("âŒ æœªæ‰¾åˆ°æ–‡æ¡£ï¼Œè¯·åœ¨ data/rumors/ ä¸­æ·»åŠ  .txt æ–‡ä»¶")
            return False
            
        print(f"ğŸ“š å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # 2. æ–‡æœ¬åˆ†å‰² - æ›´æ™ºèƒ½çš„åˆ†å‰²æ–¹å¼
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " ", ""],
            keep_separator=True  # ä¿ç•™åˆ†éš”ç¬¦ï¼Œç»´æŠ¤ä¸Šä¸‹æ–‡
        )
        
        chunks = text_splitter.split_documents(documents)
        print(f"âœ‚ï¸  åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")
        
        # 3. åˆ›å»ºå‘é‡å­˜å‚¨ - ä½¿ç”¨ç°ä»£Chromaé›†æˆ
        self.vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory="./modern_vector_db",  # ä½¿ç”¨æ–°ç›®å½•é¿å…å†²çª
            collection_metadata={"hnsw:space": "cosine"}  # ä¼˜åŒ–ç›¸ä¼¼åº¦è®¡ç®—
        )
        
        # 4. åˆ›å»ºæ£€ç´¢å™¨ - æ›´çµæ´»çš„é…ç½®
        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity",  # æˆ– "mmr" æœ€å¤§è¾¹é™…ç›¸å…³æ€§
            search_kwargs={
                "k": 4,  # è¿”å›4æ¡è¯æ®
                "score_threshold": 0.5  # æœ€ä½ç›¸å…³æ€§é˜ˆå€¼
            }
        )
        
        print("âœ… ç°ä»£åŒ–çŸ¥è¯†åº“æ„å»ºå®Œæˆ")
        return True
    
    def load_existing_knowledge_base(self) -> bool:
        """åŠ è½½ç°æœ‰çŸ¥è¯†åº“"""
        if Path("./modern_vector_db").exists():
            self.vectorstore = Chroma(
                persist_directory="./modern_vector_db",
                embedding_function=self.embeddings
            )
            self.retriever = self.vectorstore.as_retriever(
                search_kwargs={"k": 4, "score_threshold": 0.5}
            )
            print("âœ… å·²åŠ è½½ç°ä»£åŒ–çŸ¥è¯†åº“")
            return True
        return False
    
    def retrieve_evidence(self, query: str, top_k: int = 3) -> List[Dict]:
        """ç°ä»£æ£€ç´¢æ–¹æ³• - æ”¯æŒæ›´å¤šå‚æ•°"""
        if not self.retriever:
            raise ValueError("è¯·å…ˆæ„å»ºæˆ–åŠ è½½çŸ¥è¯†åº“")
        
        # åŠ¨æ€è°ƒæ•´æ£€ç´¢æ•°é‡
        if top_k != self.retriever.search_kwargs.get("k", 4):
            self.retriever.search_kwargs["k"] = top_k
        
        # æ‰§è¡Œæ£€ç´¢
        docs = self.retriever.invoke(query)
        
        # æ›´ä¸°å¯Œçš„ç»“æœæ ¼å¼
        results = []
        for i, doc in enumerate(docs):
            # è®¡ç®—æ˜¾ç¤ºé•¿åº¦ï¼ˆæ™ºèƒ½æˆªæ–­ï¼‰
            content = doc.page_content
            if len(content) > 350:
                # åœ¨å¥å·å¤„æˆªæ–­ï¼Œä¿æŒå®Œæ•´æ€§
                truncate_point = content[:350].rfind('ã€‚')
                if truncate_point > 200:
                    content = content[:truncate_point+1] + "..."
                else:
                    content = content[:300] + "..."
            
            results.append({
                "rank": i + 1,
                "content": content,
                "source": Path(doc.metadata.get("source", "æœªçŸ¥")).name,
                "page": doc.metadata.get("page", 0),
                "relevance_score": float(doc.metadata.get("score", 0.0))
            })
        
        return results
    
    def create_retrieval_chain(self):
        """åˆ›å»ºç°ä»£LCELæ£€ç´¢é“¾"""
        if not self.retriever:
            raise ValueError("è¯·å…ˆæ„å»ºæˆ–åŠ è½½çŸ¥è¯†åº“")
        
        # æ›´ä¼˜é›…çš„LCELé“¾
        retrieval_chain = (
            RunnablePassthrough()
            | (lambda x: x["query"])  # æå–æŸ¥è¯¢
            | self.retriever  # ç›´æ¥ä½¿ç”¨æ£€ç´¢å™¨
            | (lambda docs: [
                {
                    "content": doc.page_content[:300] + ("..." if len(doc.page_content) > 300 else ""),
                    "source": doc.metadata.get("source", "æœªçŸ¥")
                }
                for doc in docs
            ])
        )
        
        return retrieval_chain
    
    def similarity_search_with_score(self, query: str, k: int = 3):
        """å¸¦ç›¸ä¼¼åº¦åˆ†æ•°çš„æœç´¢ï¼ˆç›´æ¥å‘é‡åº“æ“ä½œï¼‰"""
        if not self.vectorstore:
            raise ValueError("å‘é‡åº“æœªåˆå§‹åŒ–")
        
        return self.vectorstore.similarity_search_with_score(query, k=k)

# ç°ä»£åŒ–çš„æµ‹è¯•å‡½æ•°
def test_modern_retriever():
    """æµ‹è¯•ç°ä»£æ£€ç´¢å™¨"""
    import time
    
    print("ğŸ§ª æµ‹è¯•ç°ä»£åŒ–è¯æ®æ£€ç´¢å™¨")
    print("=" * 50)
    
    retriever = ModernEvidenceRetriever()
    
    start_time = time.time()
    
    # å°è¯•åŠ è½½ç°æœ‰çŸ¥è¯†åº“
    if not retriever.load_existing_knowledge_base():
        print("æ„å»ºæ–°çš„ç°ä»£åŒ–çŸ¥è¯†åº“...")
        if not retriever.build_knowledge_base():
            return
    
    load_time = time.time() - start_time
    print(f"â±ï¸  åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        {"query": "æ´‹è‘±èƒ½æ€æ­»æ„Ÿå†’ç—…æ¯’å—ï¼Ÿ", "k": 3},
        {"query": "å¦‚ä½•ç§‘å­¦é¢„é˜²æ„Ÿå†’ï¼Ÿ", "k": 2},
        {"query": "éš”å¤œæ°´çœŸçš„è‡´ç™Œå—ï¼Ÿ", "k": 3}
    ]
    
    for test in test_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {test['query']}")
        print("-" * 40)
        
        results = retriever.retrieve_evidence(test['query'], top_k=test['k'])
        
        if not results:
            print("   æœªæ‰¾åˆ°ç›¸å…³è¯æ®")
            continue
        
        for r in results:
            print(f"   [{r['rank']}] ç›¸å…³åº¦: {r['relevance_score']:.3f}")
            print(f"      å†…å®¹: {r['content']}")
            print(f"      æ¥æº: {r['source']}")
    
    # æ¼”ç¤ºç›´æ¥å‘é‡æœç´¢ï¼ˆé«˜çº§åŠŸèƒ½ï¼‰
    print("\nğŸ¯ é«˜çº§åŠŸèƒ½: å¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æœç´¢")
    query = "æ´‹è‘±å’Œæ„Ÿå†’çš„å…³ç³»"
    results_with_scores = retriever.similarity_search_with_score(query, k=2)
    
    for i, (doc, score) in enumerate(results_with_scores):
        print(f"   ç»“æœ{i+1} [åˆ†æ•°: {score:.3f}]: {doc.page_content[:150]}...")

if __name__ == "__main__":
    test_modern_retriever()