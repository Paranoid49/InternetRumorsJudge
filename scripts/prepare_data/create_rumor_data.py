#!/usr/bin/env python3
"""
è°£è¨€æ•°æ®ç”Ÿæˆè„šæœ¬
è¿è¡Œ: python create_rumor_data.py
å°†åœ¨ data/ ç›®å½•ä¸‹ç”Ÿæˆä¸¤ç§æ ¼å¼çš„æ•°æ®
"""
import os
import json
from datetime import datetime

from internet_rumors_judge.prepare_data.create_data import RUMMOR_DATASET


# å®Œæ•´çš„è°£è¨€æ•°æ®é›†ï¼ˆåŒä¸Šï¼Œå·²çœç•¥ä»¥èŠ‚çœç©ºé—´ï¼Œè¯·å°†ä¸Šé¢å®Œæ•´çš„RUMMOR_DATASETå¤åˆ¶åˆ°è¿™é‡Œï¼‰

def create_data_directory():
    """åˆ›å»ºæ•°æ®ç›®å½•ç»“æ„"""
    directories = [
        "data",
        "data/rumors_txt",
        "data/vector_db"
    ]

    for dir_path in directories:
        os.makedirs(dir_path, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path}")


def save_as_json(data):
    """ä¿å­˜ä¸ºJSONæ–‡ä»¶"""
    json_path = "../data/rumors_dataset.json"

    # æ·»åŠ å…ƒæ•°æ®
    dataset_info = {
        "name": "ä¸­æ–‡è°£è¨€é‰´å®šæ•°æ®é›†",
        "version": "1.0",
        "created_date": datetime.now().strftime("%Y-%m-%d"),
        "count": len(data),
        "description": "ç”¨äºè®­ç»ƒå’Œæµ‹è¯•è°£è¨€é‰´å®šAIåŠ©æ‰‹çš„æ•°æ®é›†",
        "categories": list(set([item["category"] for item in data])),
        "data": data
    }

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(dataset_info, f, ensure_ascii=False, indent=2)

    print(f"âœ… JSONæ•°æ®å·²ä¿å­˜: {json_path}")
    print(f"   åŒ…å« {len(data)} æ¡è°£è¨€æ•°æ®ï¼Œ{len(dataset_info['categories'])} ä¸ªç±»åˆ«")

    return json_path


def save_as_txt_files(data):
    """ä¿å­˜ä¸ºå¤šä¸ªTXTæ–‡ä»¶ï¼ˆé€‚åˆæ–‡æ¡£åŠ è½½å™¨ï¼‰"""
    txt_count = 0

    for item in data:
        # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
        safe_title = "".join(c for c in item["rumor"][:30] if c.isalnum() or c in ("_", " "))
        filename = f"{item['id']:02d}_{safe_title}.txt"
        filepath = os.path.join("data/rumors_txt", filename)

        # æ ¼å¼åŒ–å†…å®¹
        content = f"""æ ‡é¢˜ï¼šã€è¾Ÿè°£ã€‘å…³äºâ€œ{item['rumor']}â€çš„çœŸå®æƒ…å†µ
åˆ†ç±»ï¼š{item['category']}
çœŸå®æ€§ï¼š{item['truth']}
å‘å¸ƒæ—¥æœŸï¼š{item['date']}
æ•°æ®ç¼–å·ï¼šRUMOR-{item['id']:03d}
æ¥æºï¼š{item['source']}
æ ‡ç­¾ï¼š{', '.join(item['tags'])}

ã€è°£è¨€å†…å®¹ã€‘
{item['rumor']}

ã€çœŸç›¸æ ¸æŸ¥ã€‘
{item['explanation']}

ã€å…³é”®äº‹å®ã€‘
{chr(10).join(f'â€¢ {fact}' for fact in item['key_facts'])}

ã€ç»“è®ºã€‘
ç»æ ¸æŸ¥ï¼Œâ€œ{item['rumor']}â€ä¸ºä¸å®ä¿¡æ¯ã€‚å»ºè®®å¹¿å¤§ç½‘æ°‘ä¸ä¼ è°£ã€ä¸ä¿¡è°£ï¼Œä»æƒå¨æ¸ é“è·å–ä¿¡æ¯ã€‚
"""

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        txt_count += 1

    print(f"âœ… TXTæ–‡ä»¶å·²ä¿å­˜: data/rumors_txt/")
    print(f"   ç”Ÿæˆ {txt_count} ä¸ªæ–‡æœ¬æ–‡ä»¶")

    return txt_count


def save_as_single_txt(data):
    """ä¿å­˜ä¸ºå•ä¸ªå¤§æ–‡æœ¬æ–‡ä»¶ï¼ˆå¤‡ç”¨ï¼‰"""
    content_lines = []

    for item in data:
        content_lines.append(f"{'=' * 60}")
        content_lines.append(f"ID: {item['id']}")
        content_lines.append(f"è°£è¨€: {item['rumor']}")
        content_lines.append(f"åˆ†ç±»: {item['category']}")
        content_lines.append(f"çœŸç›¸: {item['truth']}")
        content_lines.append(f"æ¥æº: {item['source']}")
        content_lines.append(f"æ—¥æœŸ: {item['date']}")
        content_lines.append(f"æ ‡ç­¾: {', '.join(item['tags'])}")
        content_lines.append("")
        content_lines.append("è¯¦ç»†è§£é‡Š:")
        content_lines.append(item['explanation'])
        content_lines.append("")
        content_lines.append("å…³é”®äº‹å®:")
        for fact in item['key_facts']:
            content_lines.append(f"  â€¢ {fact}")
        content_lines.append("")

    single_txt_path = "../data/all_rumors.txt"
    with open(single_txt_path, "w", encoding="utf-8") as f:
        f.write("\n".join(content_lines))

    print(f"âœ… åˆå¹¶æ–‡æœ¬å·²ä¿å­˜: {single_txt_path}")

    return single_txt_path


def create_modern_retriever_integration_code():
    """ç”Ÿæˆå¯ç›´æ¥é›†æˆåˆ°modern_retriever.pyçš„ä»£ç """
    integration_code = '''
# ============================================
# ç›´æ¥é›†æˆåˆ° modern_retriever.py çš„æ–¹æ³•ï¼š
# åœ¨ ModernEvidenceRetriever ç±»ä¸­æ·»åŠ ä»¥ä¸‹æ–¹æ³•
# ============================================

def create_sample_documents(self):
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ï¼ˆå¦‚æœæ•°æ®ç›®å½•ä¸ºç©ºï¼‰"""
    import shutil

    sample_dir = "./data/rumors_sample"
    if os.path.exists(sample_dir):
        shutil.rmtree(sample_dir)
    os.makedirs(sample_dir, exist_ok=True)

    # è¿™é‡Œæ”¾ç½®ä¸Šé¢çš„æ•°æ®é›†...
    sample_data = [...]  # å®Œæ•´çš„RUMMOR_DATASETæ•°æ®

    print(f"ğŸ“ åˆ›å»º {len(sample_data)} ä¸ªç¤ºä¾‹æ–‡æ¡£...")
    for item in sample_data:
        filename = f"{sample_dir}/{item['id']:02d}_{item['category']}.txt"
        content = f"è°£è¨€ï¼š{item['rumor']}\\n\\nè¾Ÿè°£ï¼š{item['explanation']}\\n\\næ¥æºï¼š{item['source']}"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(content)

    print(f"âœ… ç¤ºä¾‹æ–‡æ¡£å·²åˆ›å»ºåˆ° {sample_dir}")
    return sample_dir
'''

    code_path = "../data/integration_example.py"
    with open(code_path, "w", encoding="utf-8") as f:
        f.write(integration_code)

    print(f"ğŸ“¦ é›†æˆç¤ºä¾‹ä»£ç : {code_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("è°£è¨€æ•°æ®é›†ç”Ÿæˆå·¥å…·")
    print("=" * 60)

    # åˆ›å»ºç›®å½•ç»“æ„
    create_data_directory()

    # ä½¿ç”¨å®Œæ•´çš„æ•°æ®é›†ï¼ˆè¯·ç¡®ä¿RUMMOR_DATASETå·²å®šä¹‰ï¼‰
    # è¿™é‡Œéœ€è¦ä½ å°†ä¸Šé¢çš„å®Œæ•´RUMMOR_DATASETå¤åˆ¶åˆ°æ­¤å¤„

    # ä¿å­˜ä¸ºä¸åŒæ ¼å¼
    json_file = save_as_json(RUMMOR_DATASET)
    txt_count = save_as_txt_files(RUMMOR_DATASET)
    single_txt = save_as_single_txt(RUMMOR_DATASET)

    # ç”Ÿæˆé›†æˆä»£ç 
    create_modern_retriever_integration_code()

    print("\n" + "=" * 60)
    print("ğŸ‰ æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)
    print("ç”Ÿæˆçš„æ ¼å¼ï¼š")
    print(f"  1. JSONæ ¼å¼: {json_file}")
    print(f"  2. TXTæ–‡æ¡£: data/rumors_txt/ ({txt_count}ä¸ªæ–‡ä»¶)")
    print(f"  3. åˆå¹¶æ–‡æœ¬: {single_txt}")
    print("\nä½¿ç”¨å»ºè®®ï¼š")
    print("  â€¢ ä½¿ç”¨TXTæ–‡æ¡£æµ‹è¯•modern_retriever.pyçš„æ–‡æ¡£åŠ è½½åŠŸèƒ½")
    print("  â€¢ ä½¿ç”¨JSONæ•°æ®è¿›è¡Œç¨‹åºåŒ–å¤„ç†")
    print("  â€¢ è¿è¡Œ: python modern_retriever.py æ„å»ºå‘é‡åº“")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    categories = {}
    for item in RUMMOR_DATASET:
        cat = item["category"]
        categories[cat] = categories.get(cat, 0) + 1

    print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ï¼š")
    print(f"  æ€»æ¡ç›®æ•°: {len(RUMMOR_DATASET)}")
    print(f"  ç±»åˆ«åˆ†å¸ƒ: {categories}")
    print(f"  æ—¶é—´èŒƒå›´: {min([item['date'] for item in RUMMOR_DATASET])} è‡³ "
          f"{max([item['date'] for item in RUMMOR_DATASET])}")


if __name__ == "__main__":
    # æ³¨æ„ï¼šéœ€è¦å°†å®Œæ•´çš„RUMMOR_DATASETåˆ—è¡¨å¤åˆ¶åˆ°è¿™é‡Œ
    main()